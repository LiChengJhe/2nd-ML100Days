{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 作業: \n",
    "    \n",
    "    (1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n",
    "    \n",
    "    (2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from keras.datasets import cifar10\n",
    "from keras.datasets import mnist \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy \n",
    "#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 23:04:55.172468  3728 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 23:04:55.193467  3728 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 23:04:55.197435  3728 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#    第一步：選擇模型, 順序模型是多個網絡層的線性堆疊\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "#   第二步：構建網絡層\n",
    " \n",
    "model.add(Dense( 500,input_shape=(784,))) # 輸入層，28*28=784   \n",
    "model.add(Activation('relu')) # 激活函數是relu   \n",
    "\n",
    "model.add(Dense( 500)) # 隱藏層節點500個   \n",
    "model.add(Activation('relu'))  \n",
    "\n",
    "model.add(Dense( 500)) # 隱藏層節點500個   \n",
    "model.add(Activation('relu'))  \n",
    "\n",
    "model.add(Dense( 500)) # 隱藏層節點500個   \n",
    "model.add(Activation('relu'))  \n",
    "\n",
    "model.add(Dense( 10)) # 輸出結果是10個類別，所以維度是10   \n",
    "model.add(Activation('softmax')) # 最後一層用softmax作為激活函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters：1149010\n"
     ]
    }
   ],
   "source": [
    "# 模型建立完成後，統計參數總量\n",
    "print(\"Total Parameters：%d\" % model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,149,010\n",
      "Trainable params: 1,149,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 輸出模型摘要資訊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    " SGD(隨機梯度下降) - Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "'''\n",
    "\n",
    "'''\n",
    "RMSprop- Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "rho: float >= 0.\n",
    "epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "'''\n",
    "\n",
    "opt='sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0715 23:04:55.329468  3728 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0715 23:04:55.350442  3728 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0715 23:04:55.358435  3728 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# 第三步：編譯, \n",
    "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  第四步：資料分割\n",
    "# 使用Keras自帶的mnist工具讀取數據（第一次需要聯網）\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "\n",
    "# 由於mist的輸入數據維度是(num, 28 , 28)，這裡需要把後面的維度直接拼起來變成784維   \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2 ])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2 ])  \n",
    "Y_train = (numpy.arange(10) == y_train[:, None]).astype(int)\n",
    "Y_test = (numpy.arange(10) == y_test[:, None]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size=1000\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0715 23:04:57.801722  3728 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/500\n",
      " - 1s - loss: 2.8546 - acc: 0.8200 - val_loss: 2.8835 - val_acc: 0.8201\n",
      "Epoch 2/500\n",
      " - 1s - loss: 2.8758 - acc: 0.8204 - val_loss: 2.8597 - val_acc: 0.8215\n",
      "Epoch 3/500\n",
      " - 1s - loss: 2.3962 - acc: 0.8377 - val_loss: 1.3176 - val_acc: 0.8882\n",
      "Epoch 4/500\n",
      " - 1s - loss: 0.6219 - acc: 0.9326 - val_loss: 0.2272 - val_acc: 0.9668\n",
      "Epoch 5/500\n",
      " - 1s - loss: 0.1799 - acc: 0.9719 - val_loss: 0.1639 - val_acc: 0.9741\n",
      "Epoch 6/500\n",
      " - 1s - loss: 0.1234 - acc: 0.9786 - val_loss: 0.1390 - val_acc: 0.9771\n",
      "Epoch 7/500\n",
      " - 1s - loss: 0.0957 - acc: 0.9821 - val_loss: 0.1275 - val_acc: 0.9781\n",
      "Epoch 8/500\n",
      " - 1s - loss: 0.0764 - acc: 0.9852 - val_loss: 0.1145 - val_acc: 0.9799\n",
      "Epoch 9/500\n",
      " - 1s - loss: 0.0633 - acc: 0.9874 - val_loss: 0.1088 - val_acc: 0.9804\n",
      "Epoch 10/500\n",
      " - 1s - loss: 0.0542 - acc: 0.9890 - val_loss: 0.1038 - val_acc: 0.9810\n",
      "Epoch 11/500\n",
      " - 1s - loss: 0.0471 - acc: 0.9905 - val_loss: 0.1026 - val_acc: 0.9811\n",
      "Epoch 12/500\n",
      " - 1s - loss: 0.0417 - acc: 0.9915 - val_loss: 0.0975 - val_acc: 0.9816\n",
      "Epoch 13/500\n",
      " - 1s - loss: 0.0372 - acc: 0.9926 - val_loss: 0.0959 - val_acc: 0.9821\n",
      "Epoch 14/500\n",
      " - 1s - loss: 0.0335 - acc: 0.9934 - val_loss: 0.0944 - val_acc: 0.9823\n",
      "Epoch 15/500\n",
      " - 1s - loss: 0.0305 - acc: 0.9942 - val_loss: 0.0921 - val_acc: 0.9825\n",
      "Epoch 16/500\n",
      " - 1s - loss: 0.0280 - acc: 0.9947 - val_loss: 0.0906 - val_acc: 0.9828\n",
      "Epoch 17/500\n",
      " - 1s - loss: 0.0257 - acc: 0.9952 - val_loss: 0.0890 - val_acc: 0.9830\n",
      "Epoch 18/500\n",
      " - 1s - loss: 0.0238 - acc: 0.9957 - val_loss: 0.0877 - val_acc: 0.9832\n",
      "Epoch 19/500\n",
      " - 1s - loss: 0.0220 - acc: 0.9961 - val_loss: 0.0875 - val_acc: 0.9831\n",
      "Epoch 20/500\n",
      " - 1s - loss: 0.0206 - acc: 0.9965 - val_loss: 0.0859 - val_acc: 0.9835\n",
      "Epoch 21/500\n",
      " - 1s - loss: 0.0192 - acc: 0.9967 - val_loss: 0.0848 - val_acc: 0.9835\n",
      "Epoch 22/500\n",
      " - 1s - loss: 0.0180 - acc: 0.9970 - val_loss: 0.0842 - val_acc: 0.9836\n",
      "Epoch 23/500\n",
      " - 1s - loss: 0.0170 - acc: 0.9972 - val_loss: 0.0836 - val_acc: 0.9837\n",
      "Epoch 24/500\n",
      " - 1s - loss: 0.0160 - acc: 0.9975 - val_loss: 0.0832 - val_acc: 0.9838\n",
      "Epoch 25/500\n",
      " - 1s - loss: 0.0152 - acc: 0.9977 - val_loss: 0.0823 - val_acc: 0.9840\n",
      "Epoch 26/500\n",
      " - 1s - loss: 0.0144 - acc: 0.9978 - val_loss: 0.0821 - val_acc: 0.9840\n",
      "Epoch 27/500\n",
      " - 1s - loss: 0.0138 - acc: 0.9980 - val_loss: 0.0814 - val_acc: 0.9841\n",
      "Epoch 28/500\n",
      " - 1s - loss: 0.0131 - acc: 0.9981 - val_loss: 0.0810 - val_acc: 0.9842\n",
      "Epoch 29/500\n",
      " - 1s - loss: 0.0125 - acc: 0.9982 - val_loss: 0.0803 - val_acc: 0.9844\n",
      "Epoch 30/500\n",
      " - 1s - loss: 0.0120 - acc: 0.9983 - val_loss: 0.0800 - val_acc: 0.9843\n",
      "Epoch 31/500\n",
      " - 1s - loss: 0.0115 - acc: 0.9984 - val_loss: 0.0796 - val_acc: 0.9845\n",
      "Epoch 32/500\n",
      " - 1s - loss: 0.0111 - acc: 0.9985 - val_loss: 0.0794 - val_acc: 0.9845\n",
      "Epoch 33/500\n",
      " - 1s - loss: 0.0107 - acc: 0.9986 - val_loss: 0.0789 - val_acc: 0.9847\n",
      "Epoch 34/500\n",
      " - 1s - loss: 0.0103 - acc: 0.9987 - val_loss: 0.0787 - val_acc: 0.9847\n",
      "Epoch 35/500\n",
      " - 1s - loss: 0.0100 - acc: 0.9987 - val_loss: 0.0784 - val_acc: 0.9849\n",
      "Epoch 36/500\n",
      " - 1s - loss: 0.0097 - acc: 0.9988 - val_loss: 0.0779 - val_acc: 0.9850\n",
      "Epoch 37/500\n",
      " - 1s - loss: 0.0094 - acc: 0.9988 - val_loss: 0.0778 - val_acc: 0.9851\n",
      "Epoch 38/500\n",
      " - 1s - loss: 0.0091 - acc: 0.9989 - val_loss: 0.0777 - val_acc: 0.9850\n",
      "Epoch 39/500\n",
      " - 1s - loss: 0.0089 - acc: 0.9989 - val_loss: 0.0774 - val_acc: 0.9851\n",
      "Epoch 40/500\n",
      " - 1s - loss: 0.0086 - acc: 0.9990 - val_loss: 0.0770 - val_acc: 0.9851\n",
      "Epoch 41/500\n",
      " - 1s - loss: 0.0084 - acc: 0.9991 - val_loss: 0.0769 - val_acc: 0.9852\n",
      "Epoch 42/500\n",
      " - 1s - loss: 0.0082 - acc: 0.9991 - val_loss: 0.0767 - val_acc: 0.9852\n",
      "Epoch 43/500\n",
      " - 1s - loss: 0.0081 - acc: 0.9991 - val_loss: 0.0766 - val_acc: 0.9853\n",
      "Epoch 44/500\n",
      " - 1s - loss: 0.0079 - acc: 0.9991 - val_loss: 0.0764 - val_acc: 0.9854\n",
      "Epoch 45/500\n",
      " - 1s - loss: 0.0078 - acc: 0.9992 - val_loss: 0.0765 - val_acc: 0.9854\n",
      "Epoch 46/500\n",
      " - 1s - loss: 0.0076 - acc: 0.9992 - val_loss: 0.0759 - val_acc: 0.9853\n",
      "Epoch 47/500\n",
      " - 1s - loss: 0.0075 - acc: 0.9992 - val_loss: 0.0757 - val_acc: 0.9855\n",
      "Epoch 48/500\n",
      " - 1s - loss: 0.0073 - acc: 0.9992 - val_loss: 0.0756 - val_acc: 0.9856\n",
      "Epoch 49/500\n",
      " - 1s - loss: 0.0072 - acc: 0.9993 - val_loss: 0.0755 - val_acc: 0.9857\n",
      "Epoch 50/500\n",
      " - 1s - loss: 0.0071 - acc: 0.9993 - val_loss: 0.0754 - val_acc: 0.9857\n",
      "Epoch 51/500\n",
      " - 1s - loss: 0.0070 - acc: 0.9993 - val_loss: 0.0754 - val_acc: 0.9856\n",
      "Epoch 52/500\n",
      " - 1s - loss: 0.0069 - acc: 0.9993 - val_loss: 0.0753 - val_acc: 0.9858\n",
      "Epoch 53/500\n",
      " - 1s - loss: 0.0069 - acc: 0.9993 - val_loss: 0.0750 - val_acc: 0.9858\n",
      "Epoch 54/500\n",
      " - 1s - loss: 0.0068 - acc: 0.9994 - val_loss: 0.0750 - val_acc: 0.9857\n",
      "Epoch 55/500\n",
      " - 1s - loss: 0.0067 - acc: 0.9994 - val_loss: 0.0749 - val_acc: 0.9859\n",
      "Epoch 56/500\n",
      " - 1s - loss: 0.0066 - acc: 0.9994 - val_loss: 0.0751 - val_acc: 0.9858\n",
      "Epoch 57/500\n",
      " - 1s - loss: 0.0066 - acc: 0.9994 - val_loss: 0.0748 - val_acc: 0.9859\n",
      "Epoch 58/500\n",
      " - 1s - loss: 0.0065 - acc: 0.9994 - val_loss: 0.0748 - val_acc: 0.9859\n",
      "Epoch 59/500\n",
      " - 1s - loss: 0.0065 - acc: 0.9994 - val_loss: 0.0746 - val_acc: 0.9859\n",
      "Epoch 60/500\n",
      " - 1s - loss: 0.0064 - acc: 0.9994 - val_loss: 0.0746 - val_acc: 0.9859\n",
      "Epoch 61/500\n",
      " - 1s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0746 - val_acc: 0.9859\n",
      "Epoch 62/500\n",
      " - 1s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0745 - val_acc: 0.9860\n",
      "Epoch 63/500\n",
      " - 1s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0744 - val_acc: 0.9861\n",
      "Epoch 64/500\n",
      " - 1s - loss: 0.0062 - acc: 0.9994 - val_loss: 0.0743 - val_acc: 0.9861\n",
      "Epoch 65/500\n",
      " - 1s - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0743 - val_acc: 0.9861\n",
      "Epoch 66/500\n",
      " - 1s - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0743 - val_acc: 0.9861\n",
      "Epoch 67/500\n",
      " - 1s - loss: 0.0061 - acc: 0.9995 - val_loss: 0.0742 - val_acc: 0.9861\n",
      "Epoch 68/500\n",
      " - 1s - loss: 0.0061 - acc: 0.9995 - val_loss: 0.0740 - val_acc: 0.9861\n",
      "Epoch 69/500\n",
      " - 1s - loss: 0.0061 - acc: 0.9995 - val_loss: 0.0741 - val_acc: 0.9862\n",
      "Epoch 70/500\n",
      " - 1s - loss: 0.0060 - acc: 0.9995 - val_loss: 0.0740 - val_acc: 0.9862\n",
      "Epoch 71/500\n",
      " - 1s - loss: 0.0060 - acc: 0.9995 - val_loss: 0.0740 - val_acc: 0.9862\n",
      "Epoch 72/500\n",
      " - 1s - loss: 0.0060 - acc: 0.9995 - val_loss: 0.0739 - val_acc: 0.9863\n",
      "Epoch 73/500\n",
      " - 1s - loss: 0.0060 - acc: 0.9995 - val_loss: 0.0739 - val_acc: 0.9863\n",
      "Epoch 74/500\n",
      " - 1s - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0739 - val_acc: 0.9863\n",
      "Epoch 75/500\n",
      " - 1s - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0738 - val_acc: 0.9862\n",
      "Epoch 76/500\n",
      " - 1s - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0737 - val_acc: 0.9863\n",
      "Epoch 77/500\n",
      " - 1s - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0737 - val_acc: 0.9863\n",
      "Epoch 78/500\n",
      " - 1s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0737 - val_acc: 0.9863\n",
      "Epoch 79/500\n",
      " - 1s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0736 - val_acc: 0.9863\n",
      "Epoch 80/500\n",
      " - 1s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0735 - val_acc: 0.9864\n",
      "Epoch 81/500\n",
      " - 1s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0735 - val_acc: 0.9863\n",
      "Epoch 82/500\n",
      " - 1s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0735 - val_acc: 0.9864\n",
      "Epoch 83/500\n",
      " - 1s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0735 - val_acc: 0.9864\n",
      "Epoch 84/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0734 - val_acc: 0.9864\n",
      "Epoch 85/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0734 - val_acc: 0.9864\n",
      "Epoch 86/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0733 - val_acc: 0.9864\n",
      "Epoch 87/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0733 - val_acc: 0.9864\n",
      "Epoch 88/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0732 - val_acc: 0.9864\n",
      "Epoch 89/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0732 - val_acc: 0.9864\n",
      "Epoch 90/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0732 - val_acc: 0.9864\n",
      "Epoch 91/500\n",
      " - 1s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0732 - val_acc: 0.9865\n",
      "Epoch 92/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0732 - val_acc: 0.9865\n",
      "Epoch 93/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0731 - val_acc: 0.9865\n",
      "Epoch 94/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0731 - val_acc: 0.9865\n",
      "Epoch 95/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0731 - val_acc: 0.9865\n",
      "Epoch 96/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0730 - val_acc: 0.9865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0730 - val_acc: 0.9866\n",
      "Epoch 98/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0729 - val_acc: 0.9865\n",
      "Epoch 99/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0730 - val_acc: 0.9866\n",
      "Epoch 100/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0729 - val_acc: 0.9865\n",
      "Epoch 101/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0729 - val_acc: 0.9865\n",
      "Epoch 102/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0729 - val_acc: 0.9866\n",
      "Epoch 103/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0728 - val_acc: 0.9866\n",
      "Epoch 104/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0728 - val_acc: 0.9865\n",
      "Epoch 105/500\n",
      " - 1s - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0728 - val_acc: 0.9866\n",
      "Epoch 106/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0728 - val_acc: 0.9866\n",
      "Epoch 107/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0727 - val_acc: 0.9866\n",
      "Epoch 108/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0727 - val_acc: 0.9866\n",
      "Epoch 109/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0727 - val_acc: 0.9866\n",
      "Epoch 110/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9866\n",
      "Epoch 111/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9866\n",
      "Epoch 112/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9866\n",
      "Epoch 113/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9866\n",
      "Epoch 114/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9866\n",
      "Epoch 115/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0725 - val_acc: 0.9867\n",
      "Epoch 116/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0725 - val_acc: 0.9866\n",
      "Epoch 117/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0725 - val_acc: 0.9867\n",
      "Epoch 118/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0725 - val_acc: 0.9866\n",
      "Epoch 119/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0725 - val_acc: 0.9866\n",
      "Epoch 120/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0725 - val_acc: 0.9867\n",
      "Epoch 121/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9867\n",
      "Epoch 122/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9868\n",
      "Epoch 123/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9867\n",
      "Epoch 124/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9867\n",
      "Epoch 125/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9867\n",
      "Epoch 126/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9867\n",
      "Epoch 127/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9867\n",
      "Epoch 128/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0723 - val_acc: 0.9867\n",
      "Epoch 129/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0723 - val_acc: 0.9867\n",
      "Epoch 130/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0723 - val_acc: 0.9868\n",
      "Epoch 131/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0723 - val_acc: 0.9868\n",
      "Epoch 132/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0723 - val_acc: 0.9868\n",
      "Epoch 133/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9868\n",
      "Epoch 134/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9868\n",
      "Epoch 135/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9868\n",
      "Epoch 136/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9868\n",
      "Epoch 137/500\n",
      " - 1s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9868\n",
      "Epoch 138/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9868\n",
      "Epoch 139/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9868\n",
      "Epoch 140/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9868\n",
      "Epoch 141/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9869\n",
      "Epoch 142/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9869\n",
      "Epoch 143/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9869\n",
      "Epoch 144/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9869\n",
      "Epoch 145/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9869\n",
      "Epoch 146/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 147/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9869\n",
      "Epoch 148/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 149/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 150/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 151/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 152/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 153/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0720 - val_acc: 0.9869\n",
      "Epoch 154/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 155/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 156/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 157/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 158/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 159/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 160/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9869\n",
      "Epoch 161/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 162/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9870\n",
      "Epoch 163/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 164/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 165/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 166/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 167/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 168/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 169/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 170/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 171/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9870\n",
      "Epoch 172/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 173/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 174/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 175/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9870\n",
      "Epoch 176/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 177/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 178/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 179/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 180/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 181/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 182/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "Epoch 183/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9871\n",
      "Epoch 184/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 185/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 186/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 187/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 188/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 189/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 190/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 191/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n",
      "Epoch 192/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0716 - val_acc: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 194/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 195/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 196/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 197/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 198/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 199/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 200/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 201/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 202/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 203/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 204/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 205/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 206/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0715 - val_acc: 0.9872\n",
      "Epoch 207/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 208/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9872\n",
      "Epoch 209/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 210/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 211/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 212/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 213/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 214/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 215/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 216/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 217/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 218/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 219/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 220/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 221/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0714 - val_acc: 0.9873\n",
      "Epoch 222/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 223/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 224/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 225/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 226/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 227/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 228/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 229/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 230/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 231/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 232/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 233/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 234/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 235/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 236/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0713 - val_acc: 0.9874\n",
      "Epoch 237/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 238/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 239/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 240/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 241/500\n",
      " - 1s - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 242/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 243/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 244/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 245/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 246/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 247/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 248/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 249/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 250/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9875\n",
      "Epoch 251/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9875\n",
      "Epoch 252/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 253/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0712 - val_acc: 0.9874\n",
      "Epoch 254/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 255/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 256/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 257/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 258/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 259/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 260/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 261/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 262/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 263/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 264/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 265/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 266/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 267/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 268/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 269/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 270/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 271/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 272/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 273/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 274/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0711 - val_acc: 0.9875\n",
      "Epoch 275/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 276/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 277/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 278/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 279/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 280/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 281/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 282/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 283/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 284/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 285/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 286/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 287/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 288/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9876\n",
      "Epoch 290/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 291/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9876\n",
      "Epoch 292/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9876\n",
      "Epoch 293/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0710 - val_acc: 0.9876\n",
      "Epoch 294/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 295/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 296/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9875\n",
      "Epoch 297/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 298/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 299/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 300/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 301/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 302/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 303/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 304/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 305/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 306/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 307/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 308/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 309/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 310/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 311/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 312/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 313/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 314/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 315/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 316/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 317/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 318/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 319/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 320/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 321/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 322/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 323/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 324/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 325/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 326/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 327/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 328/500\n",
      " - 1s - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9876\n",
      "Epoch 329/500\n",
      " - 1s - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 330/500\n",
      " - 1s - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0709 - val_acc: 0.9877\n",
      "Epoch 331/500\n",
      " - 1s - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 332/500\n",
      " - 1s - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 333/500\n",
      " - 1s - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 334/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 335/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 336/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 337/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 338/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 339/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 340/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 341/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 342/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0708 - val_acc: 0.9877\n",
      "Epoch 343/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 344/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 345/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 346/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 347/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 348/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 349/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 350/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 351/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 352/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 353/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9877\n",
      "Epoch 354/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 355/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9877\n",
      "Epoch 356/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0707 - val_acc: 0.9878\n",
      "Epoch 357/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9877\n",
      "Epoch 358/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9877\n",
      "Epoch 359/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 360/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 361/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 362/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9877\n",
      "Epoch 363/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 364/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 365/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9877\n",
      "Epoch 366/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 367/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 368/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 369/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 370/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 371/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 372/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 373/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 374/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 375/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9878\n",
      "Epoch 376/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 377/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 378/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 379/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 380/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 381/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 382/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 383/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 384/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 386/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 387/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 388/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 389/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 390/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 391/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 392/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 393/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 394/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 395/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 396/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 397/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 398/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9878\n",
      "Epoch 399/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0705 - val_acc: 0.9879\n",
      "Epoch 400/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 401/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 402/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 403/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 404/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 405/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 406/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 407/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 408/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 409/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 410/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 411/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 412/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 413/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 414/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 415/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9878\n",
      "Epoch 416/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 417/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 418/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 419/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 420/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 421/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 422/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 423/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 424/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 425/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 426/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 427/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 428/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 429/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 430/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 431/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0704 - val_acc: 0.9879\n",
      "Epoch 432/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 433/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 434/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 435/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 436/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 437/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 438/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 439/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 440/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 441/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 442/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 443/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 444/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 445/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 446/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 447/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 448/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 449/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 450/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 451/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 452/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 453/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 454/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 455/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 456/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 457/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 458/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 459/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 460/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 461/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 462/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 463/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 464/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 465/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 466/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 467/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0703 - val_acc: 0.9879\n",
      "Epoch 468/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 469/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 470/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 471/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 472/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 473/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 474/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 475/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 476/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 477/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 478/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 479/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 480/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 482/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 483/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 484/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 485/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 486/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 487/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9879\n",
      "Epoch 488/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 489/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 490/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 491/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 492/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 493/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 494/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 495/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 496/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 497/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 498/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 499/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n",
      "Epoch 500/500\n",
      " - 1s - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0702 - val_acc: 0.9880\n"
     ]
    }
   ],
   "source": [
    "# 第五步：訓練, 修正 model 參數\n",
    "\n",
    "history = model.fit(X_train,Y_train,batch_size = batch_size, epochs=epochs, shuffle=True,verbose=2,validation_split=0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test set \n",
      "\n",
      " The test loss is %f  [0.06263590788526927, 0.9887800228595733]\n",
      "\n",
      " The accuracy of the model is 0.943600 \n"
     ]
    }
   ],
   "source": [
    "#    第六步：輸出\n",
    " \n",
    "print ( \" test set \" )\n",
    "scores = model.evaluate(X_test,Y_test,batch_size=200,verbose= 0)\n",
    "print ( \"\" )\n",
    "#print ( \" The test loss is %f \" % scores)\n",
    "print ( \" The test loss is %f \", scores)\n",
    "result = model.predict(X_test,batch_size=200,verbose= 0)\n",
    "\n",
    "result_max = numpy.argmax(result, axis = 1 )\n",
    "test_max = numpy.argmax(Y_test, axis = 1 )\n",
    "\n",
    "result_bool = numpy.equal(result_max, test_max)\n",
    "true_num = numpy.sum(result_bool)\n",
    "print ( \"\" )\n",
    "print ( \" The accuracy of the model is %f \" % (true_num/len(result_bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
